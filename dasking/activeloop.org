#+TITLE: Backlog

* Week 1
** Monday [Understanding the Task]
1. Probation Task
https://github.com/activeloopai/Hub/issues/22
2. ImageNet Kaggle Repository
https://www.kaggle.com/c/imagenet-object-localization-challenge
Recommendations
3. ImageNet Original Repository
https://patrykchrabaszcz.github.io/Imagenet32/
** Tuesday [Loading the Imagenet Dataset]
I've understood the task correctly: you want me to add some kind of wrapper (or adaptor) for yet another ImageNet dataset along with COCO, CIFAR, and MNIST. I've installed all of the Hub dependencies and looked through your code. In fact I understand every single line of your code from the pythonic viewpoint, but I could not catch the semantics and the teams' vision of how the project should be organized, evolved, executed and tested. It is normal for innovative entrepreneurships. I need some comments about some design decisions of the Hub and ajdoint projects. Could you explain me the following things that look like simple but not obvious for a freshman. Also my thoughts could play be a source of inspiration for writing a good manual.  If I touched too much topics we could make a Zoom brainstorming session today. (edited)

1. [Dataset] Why it is crucial to wrap the torchvision version of Imagenet instead of the original dataset itself? Does it shares the same guidelines structuring the folders and will it be compatible with other frameworks like tensorflow? To complete the task should I dive deep into the Imagenet structure or treat it as a black box? I wanted to discover it by myself http://image-net.org/, but I'll need a permission to get access.
10:05
2. [Development] How to organize the development process and experimentation? Should I clone the Hub repo, modify it and reinstall, or should I modify the installed version? Where to download the Imagenet and how to approve the folders? During the implementation process will my experiments affect the cloud computing services or they will done locally? How to execute the loading function directly?
10:07
3. [Algorithm] Could you clarify the algorithm (with steps, input and output params) that loads the listed above datasets? Why do we need parsers in dataset loaders? The loading process combine serialized objects (pickles) and images, could you explain the destination of the first ones? Why you modify the images while loading!? (for example, reshape) It's natural to assume that the data should be immutable while loading. The Hub Dtag should contain the following meta information (default, image, text, box, mask, segmentation, video, embedding, tabular, time, event, audio, pointcloud, landmark, polygon, mesh, document. Which one of the are obligatory and when they should be initialized (while loading or while processing. Should the loader copy the data or not?
** Wednesday [Parsing the Imagenet Dataset]
1. Got access to ImageNet image dataset through Skoltech account because it turned out that 2017 kaggle repository is forbidden.
2. Understood the dataset structure
   ImageNet is supplied in different versions clissified
    a. by year of ILSVRC (2010 - 2017) or Stanform course
    b. by ML task (classification, localization)
    c. by image size (8x8, 16x16, 32x32, 64x64)
    The original dataset has a huge size (~15 Gb) so I've chosed a downsampled ILSVRC a downsampled variant of  ImageNet as an alternative to the CIFAR datasets. The Stanford Version of Dataset is decomposed into 3 parts: training, validation, and testing, the orinial ILSVRC version -- only in two parts (training and validation). Our downsampled datasets contain exactly the same number of images as the original ImageNet, i.e., 1281167 training images from 1000 classes and 50000 validation images with 50 images per class.
3. Wrote Unix-like CLI parsers
    #+BEGIN_SRC sh
    # python3 examples/imgnet/upload_imgnet8.py -i ./data/imgnet8 -o ./data/imgnet8_processed
    #+END_SRC
4. Discovered loading procedures
    The file format was inspired by the CIFAR dataset.
    #+BEGIN_SRC python
    #def unpickle(file):
    #with open(file, 'rb') as fo:
    #    dict = pickle.load(fo)
    #return dict
    #+END_SRC
5. I've read the code of all torchvision dataset loaders: caltech, cityscapes, flickr, imagenet, lsun, phototour, semeion, ucf101, video_utils, celeba, coco, mnist, sbd, stl10, usps, vision, cifar, fakedata, hmdb51, kinetics, omniglot, sbu, svhn, utils, vocsconception (equal names)
from hub import datasets
from hub.collection import dataset

Would you clarify the following lines of github issue 22
from hub import datasets
ds = datasets.from_pytorch(imagenet)

There is no submodule <<datasets>> in the <<hub>> module. You obligated me to implement it or this is an approximate version what you want to see in subsequent versions?
Are you sure that generic approach for data loading is possible? If it is so that there exist some single systematic way to turn all the loaded objects into hub tensors. But the trouble is that the dataset contents is very heterogenious, every loader extracts different data (images, video, text) from a different set of files (without any naming convention). Though each dataset requires individual approach of loading. The only way I see is to develop unique loader for every individual dataset and then switch the case according to the user needs. The root of this issue that best practices for dataset handling have not formed yet and only manual approach matters. This means that I will have to download all the datasets and buld individual loaders and that combine them as condition cases of from_pytorch function.
** Thursday [Loading the Imagenet Dataset]
1. Implemented a custom data loader of imagenet by pytorch
** Friday [Comparing the Dataset Loaders]

* Week 2
** Monday [Tensorflow Dataset Loaders]
*** Algorithm
1. Loading the data
There are too much parameters of loading, we should decide how to set up default config
#+BEGIN_SRC python
    tfds.load(
        name, split=None, data_dir=None, batch_size=None, shuffle_files=False,
        download=True, as_supervised=False, decoders=None, read_config=None,
        with_info=False, builder_kwargs=None, download_and_prepare_kwargs=None,
        as_dataset_kwargs=None, try_gcs=False
    )
#+END_SRC
Wrapper around tfds.core.DatasetBuilder that loads the named dataset into a tf.data.Dataset.
#+BEGIN_SRC python
    builder = tfds.builder(name, data_dir=data_dir, **builder_kwargs)
    if download:
        builder.download_and_prepare(**download_and_prepare_kwargs)
    ds = builder.as_dataset(
        split=split, as_supervised=as_supervised, **as_dataset_kwargs)
    if with_info:
        return ds, builder.info
    return ds
#+END_SRC
*** Questions
1. What does the store function also loads the saved dataframe?
#+BEGIN_SRC python
    return load(tag, creds)
#+END_SRC
2. Why each row of the dataset have the fields: 'data' and 'labels' (not 'label')?
3. Who do you use EagerTensor inside Hub Dataset format?
*** Why
how tow use it citation licence description
* Tensorflow Datasets
Hub Dtag
1. document, object are json formats?
    Dtag and Dtype, eager tensor slicing, masking.
2. Python None type is not serializable, we should have explicit 'unknown' or 'any' dtag
3. Iterators (by dicts and by tuples)
4. Smart compression
        tensors[feature] = hub_tensor.from_array(data, dtag=dtag, dcompress=codec)
5. Tensorflow Dtype represents all the scalar types tf.int*, tf.float*, tf.string and etc.

| Dtag         | Shape                                                                    | Types      |
|--------------+--------------------------------------------------------------------------+------------|
| tensor       | tensor over any Dtype                                                    | any        |
| image        | (width, height), (channel, width, height) or (width, height, channel)    | int, float |
| text         | used for label                                                           |            |
| box          | [(4)]                                                                    | int32      |
| mask         | (width, height)                                                          | bool       |
| segmentation | (width, height), (channel, width, height) or (width, height, channel)    | int        |
| video        | (sequence, width, height, channel) or (sequence, channel, width, height) | int, float |
| embedding    |                                                                          |            |
| tabular      |                                                                          |            |
| time         |                                                                          |            |
| event        |                                                                          |            |
| audio        |                                                                          |            |
| pointcloud   |                                                                          |            |
| landmark     |                                                                          |            |
| polygon      |                                                                          |            |
| mesh         |                                                                          |            |
| document     |                                                                          |            |
| none         |                                                                          |            |


TENSORFLOW DATASETS


AUDIO

common voice
FeaturesDict({
    'accent': ClassLabel(shape=(), dtype=tf.int64, num_classes=17),
    'age': Text(shape=(), dtype=tf.string),
    'client_id': Text(shape=(), dtype=tf.string),
    'downvotes': tf.int32,
    'gender': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
    'sentence': Text(shape=(), dtype=tf.string),
    'upvotes': tf.int32,
    'voice': Audio(shape=(None,), dtype=tf.int64),
})

crema_d
FeaturesDict({
    'audio': Audio(shape=(None,), dtype=tf.int64),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),
    'speaker_id': tf.string,
})

dementiabank
FeaturesDict({
    'audio': Audio(shape=(None,), dtype=tf.int64),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'speaker_id': tf.string,
})

fuss
FeaturesDict({
    'id': tf.string,
    'jams': tf.string,
    'mixture_audio': Audio(shape=(160000,), dtype=tf.int16),
    'segments': Sequence({
        'end_time_seconds': tf.float32,
        'label': tf.string,
        'start_time_seconds': tf.float32,
    }),
    'sources': Sequence({
        'audio': Audio(shape=(160000,), dtype=tf.int16),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),
    }),
})

groove
FeaturesDict({
    'bpm': tf.int32,
    'drummer': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    'id': tf.string,
    'midi': tf.string,
    'style': FeaturesDict({
        'primary': ClassLabel(shape=(), dtype=tf.int64, num_classes=18),
        'secondary': tf.string,
    }),
    'time_signature': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
    'type': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
})

librispeech
FeaturesDict({
    'chapter_id': tf.int64,
    'id': tf.string,
    'speaker_id': tf.int64,
    'speech': Audio(shape=(None,), dtype=tf.int64),
    'text': Text(shape=(), dtype=tf.string),
})

libritts
FeaturesDict({
    'chapter_id': tf.int64,
    'id': tf.string,
    'speaker_id': tf.int64,
    'speech': Audio(shape=(None,), dtype=tf.int64),
    'text_normalized': Text(shape=(), dtype=tf.string),
    'text_original': Text(shape=(), dtype=tf.string),
})

ljspeech
FeaturesDict({
    'id': tf.string,
    'speech': Audio(shape=(None,), dtype=tf.int64),
    'text': Text(shape=(), dtype=tf.string),
    'text_normalized': Text(shape=(), dtype=tf.string),
})

nsynth
FeaturesDict({
    'audio': Audio(shape=(64000,), dtype=tf.float32),
    'id': tf.string,
    'instrument': FeaturesDict({
        'family': ClassLabel(shape=(), dtype=tf.int64, num_classes=11),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=1006),
        'source': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
    }),
    'pitch': ClassLabel(shape=(), dtype=tf.int64, num_classes=128),
    'qualities': FeaturesDict({
        'bright': tf.bool,
        'dark': tf.bool,
        'distortion': tf.bool,
        'fast_decay': tf.bool,
        'long_release': tf.bool,
        'multiphonic': tf.bool,
        'nonlinear_env': tf.bool,
        'percussive': tf.bool,
        'reverb': tf.bool,
        'tempo-synced': tf.bool,
    }),
    'velocity': ClassLabel(shape=(), dtype=tf.int64, num_classes=128),
})

savee
FeaturesDict({
    'audio': Audio(shape=(None,), dtype=tf.int64),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=7),
    'speaker_id': tf.string,
})

speech_commands
FeaturesDict({
    'audio': Audio(shape=(None,), dtype=tf.int64),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=12),
})

tedium
FeaturesDict({
    'gender': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
    'id': tf.string,
    'speaker_id': tf.string,
    'speech': Audio(shape=(None,), dtype=tf.int64),
    'text': Text(shape=(), dtype=tf.string),
})

vctk
FeaturesDict({
    'accent': ClassLabel(shape=(), dtype=tf.int64, num_classes=13),
    'gender': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'id': tf.string,
    'speaker': ClassLabel(shape=(), dtype=tf.int64, num_classes=110),
    'speech': Audio(shape=(None,), dtype=tf.int64),
    'text': Text(shape=(), dtype=tf.string),
})

voxceleb
FeaturesDict({
    'audio': Audio(shape=(None,), dtype=tf.int64),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=1252),
})

voxforge
FeaturesDict({
    'audio': Audio(shape=(None,), dtype=tf.int64),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),
    'speaker_id': tf.string,
})

# IMAGE

abstract_reasoning
FeaturesDict({
    'answers': Video(Image(shape=(160, 160, 1), dtype=tf.uint8)),
    'context': Video(Image(shape=(160, 160, 1), dtype=tf.uint8)),
    'filename': Text(shape=(), dtype=tf.string),
    'meta_target': Tensor(shape=(12,), dtype=tf.int64),
    'relation_structure_encoded': Tensor(shape=(4, 12), dtype=tf.int64),
    'target': ClassLabel(shape=(), dtype=tf.int64, num_classes=8),
})

aflw2k3d
FeaturesDict({
    'image': Image(shape=(450, 450, 3), dtype=tf.uint8),
    'landmarks_68_3d_xy_normalized': Tensor(shape=(68, 2), dtype=tf.float32),
    'landmarks_68_3d_z': Tensor(shape=(68, 1), dtype=tf.float32),
})

arc
FeaturesDict({
    'task_id': Text(shape=(), dtype=tf.string),
    'test': Sequence({
        'input': Sequence(Sequence(tf.int32)),
        'output': Sequence(Sequence(tf.int32)),
    }),
    'train': Sequence({
        'input': Sequence(Sequence(tf.int32)),
        'output': Sequence(Sequence(tf.int32)),
    }),
})

binarized_mnist
FeaturesDict({
    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
})

Celeb
FeaturesDict({
    'attributes': FeaturesDict({
        '5_o_Clock_Shadow': tf.bool,
        'Arched_Eyebrows': tf.bool,
        'Attractive': tf.bool,
        'Bags_Under_Eyes': tf.bool,
        'Bald': tf.bool,
        'Bangs': tf.bool,
        'Big_Lips': tf.bool,
        'Big_Nose': tf.bool,
        'Black_Hair': tf.bool,
        'Blond_Hair': tf.bool,
        'Blurry': tf.bool,
        'Brown_Hair': tf.bool,
        'Bushy_Eyebrows': tf.bool,
        'Chubby': tf.bool,
        'Double_Chin': tf.bool,
        'Eyeglasses': tf.bool,
        'Goatee': tf.bool,
        'Gray_Hair': tf.bool,
        'Heavy_Makeup': tf.bool,
        'High_Cheekbones': tf.bool,
        'Male': tf.bool,
        'Mouth_Slightly_Open': tf.bool,
        'Mustache': tf.bool,
        'Narrow_Eyes': tf.bool,
        'No_Beard': tf.bool,
        'Oval_Face': tf.bool,
        'Pale_Skin': tf.bool,
        'Pointy_Nose': tf.bool,
        'Receding_Hairline': tf.bool,
        'Rosy_Cheeks': tf.bool,
        'Sideburns': tf.bool,
        'Smiling': tf.bool,
        'Straight_Hair': tf.bool,
        'Wavy_Hair': tf.bool,
        'Wearing_Earrings': tf.bool,
        'Wearing_Hat': tf.bool,
        'Wearing_Lipstick': tf.bool,
        'Wearing_Necklace': tf.bool,
        'Wearing_Necktie': tf.bool,
        'Young': tf.bool,
    }),
    'image': Image(shape=(218, 178, 3), dtype=tf.uint8),
    'landmarks': FeaturesDict({
        'lefteye_x': tf.int64,
        'lefteye_y': tf.int64,
        'leftmouth_x': tf.int64,
        'leftmouth_y': tf.int64,
        'nose_x': tf.int64,
        'nose_y': tf.int64,
        'righteye_x': tf.int64,
        'righteye_y': tf.int64,
        'rightmouth_x': tf.int64,
        'rightmouth_y': tf.int64,
    }),
})

*celeb_a_nq
FeaturesDict({
    'image': Image(shape=(1024, 1024, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
})

*clevr
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'objects': Sequence({
        '3d_coords': Tensor(shape=(3,), dtype=tf.float32),
        'color': ClassLabel(shape=(), dtype=tf.int64, num_classes=8),
        'material': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
        'pixel_coords': Tensor(shape=(3,), dtype=tf.float32),
        'rotation': tf.float32,
        'shape': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
        'size': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    }),
    'question_answer': Sequence({
        'answer': Text(shape=(), dtype=tf.string),
        'question': Text(shape=(), dtype=tf.string),
    }),
})

clic
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
})

coil100
FeaturesDict({
    'image': Image(shape=(128, 128, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=72),
    'object_id': Text(shape=(), dtype=tf.string),
})

div2k
FeaturesDict({
    'hr': Image(shape=(None, None, 3), dtype=tf.uint8),
    'lr': Image(shape=(None, None, 3), dtype=tf.uint8),
})

downsampled_imagenet
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
})

dsprites
O

*Common Voice
    FeaturesDict({
        'accent': ClassLabel(shape=(), dtype=tf.int64, num_classes=17),
        'age': Text(shape=(), dtype=tf.string),
        'client_id': Text(shape=(), dtype=tf.string),
        'downvotes': tf.int32,
        'gender': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
        'sentence': Text(shape=(), dtype=tf.string),
        'upvotes': tf.int32,
        'voice': Audio(shape=(None,), dtype=tf.int64),
    })
FeaturesDict({
    'audio': Audio(shape=(None,), dtype=tf.int64),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),
    'speaker_id': tf.string,
})
FeaturesDict({
    'audio': Audio(shape=(None,), dtype=tf.int64),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'speaker_id': tf.string,
})
FeaturesDict({
    'id': tf.string,
    'jams': tf.string,
    'mixture_audio': Audio(shape=(160000,), dtype=tf.int16),
    'segments': Sequence({
        'end_time_seconds': tf.float32,
        'label': tf.string,
        'start_time_seconds': tf.float32,
    }),
    'sources': Sequence({
        'audio': Audio(shape=(160000,), dtype=tf.int16),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),
    }),
})
FeaturesDict({
    'bpm': tf.int32,
    'drummer': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    'id': tf.string,
    'midi': tf.string,
    'style': FeaturesDict({
        'primary': ClassLabel(shape=(), dtype=tf.int64, num_classes=18),
        'secondary': tf.string,
    }),
    'time_signature': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
    'type': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
})

FeaturesDict({
    'chapter_id': tf.int64,
    'id': tf.string,
    'speaker_id': tf.int64,
    'speech': Audio(shape=(None,), dtype=tf.int64),
    'text': Text(shape=(), dtype=tf.string),
})

FeaturesDict({
    'chapter_id': tf.int64,
    'id': tf.string,
    'speaker_id': tf.int64,
    'speech': Audio(shape=(None,), dtype=tf.int64),
    'text_normalized': Text(shape=(), dtype=tf.string),
    'text_original': Text(shape=(), dtype=tf.string),
})

FeaturesDict({
    'id': tf.string,
    'speech': Audio(shape=(None,), dtype=tf.int64),
    'text': Text(shape=(), dtype=tf.string),
    'text_normalized': Text(shape=(), dtype=tf.string),
})

FeaturesDict({
    'audio': Audio(shape=(64000,), dtype=tf.float32),
    'id': tf.string,
    'instrument': FeaturesDict({
        'family': ClassLabel(shape=(), dtype=tf.int64, num_classes=11),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=1006),
        'source': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
    }),
    'pitch': ClassLabel(shape=(), dtype=tf.int64, num_classes=128),
    'qualities': FeaturesDict({
        'bright': tf.bool,
        'dark': tf.bool,
        'distortion': tf.bool,
        'fast_decay': tf.bool,
        'long_release': tf.bool,
        'multiphonic': tf.bool,
        'nonlinear_env': tf.bool,
        'percussive': tf.bool,
        'reverb': tf.bool,
        'tempo-synced': tf.bool,
    }),
    'velocity': ClassLabel(shape=(), dtype=tf.int64, num_classes=128),
})

FeaturesDict({
    'audio': Audio(shape=(None,), dtype=tf.int64),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=7),
    'speaker_id': tf.string,
})

FeaturesDict({
    'audio': Audio(shape=(None,), dtype=tf.int64),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=12),
})

FeaturesDict({
    'gender': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
    'id': tf.string,
    'speaker_id': tf.string,
    'speech': Audio(shape=(None,), dtype=tf.int64),
    'text': Text(shape=(), dtype=tf.string),
})

FeaturesDict({
    'accent': ClassLabel(shape=(), dtype=tf.int64, num_classes=13),
    'gender': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'id': tf.string,
    'speaker': ClassLabel(shape=(), dtype=tf.int64, num_classes=110),
    'speech': Audio(shape=(None,), dtype=tf.int64),
    'text': Text(shape=(), dtype=tf.string),
})

FeaturesDict({
    'audio': Audio(shape=(None,), dtype=tf.int64),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=1252),
})

FeaturesDict({
    'audio': Audio(shape=(None,), dtype=tf.int64),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),
    'speaker_id': tf.string,
})

# IMAGE
FeaturesDict({
    'answers': Video(Image(shape=(160, 160, 1), dtype=tf.uint8)),
    'context': Video(Image(shape=(160, 160, 1), dtype=tf.uint8)),
    'filename': Text(shape=(), dtype=tf.string),
    'meta_target': Tensor(shape=(12,), dtype=tf.int64),
    'relation_structure_encoded': Tensor(shape=(4, 12), dtype=tf.int64),
    'target': ClassLabel(shape=(), dtype=tf.int64, num_classes=8),
})

FeaturesDict({
    'image': Image(shape=(450, 450, 3), dtype=tf.uint8),
    'landmarks_68_3d_xy_normalized': Tensor(shape=(68, 2), dtype=tf.float32),
    'landmarks_68_3d_z': Tensor(shape=(68, 1), dtype=tf.float32),
})

FeaturesDict({
    'task_id': Text(shape=(), dtype=tf.string),
    'test': Sequence({
        'input': Sequence(Sequence(tf.int32)),
        'output': Sequence(Sequence(tf.int32)),
    }),
    'train': Sequence({
        'input': Sequence(Sequence(tf.int32)),
        'output': Sequence(Sequence(tf.int32)),
    }),
})

FeaturesDict({
    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
})

Celeb
FeaturesDict({
    'attributes': FeaturesDict({
        '5_o_Clock_Shadow': tf.bool,
        'Arched_Eyebrows': tf.bool,
        'Attractive': tf.bool,
        'Bags_Under_Eyes': tf.bool,
        'Bald': tf.bool,
        'Bangs': tf.bool,
        'Big_Lips': tf.bool,
        'Big_Nose': tf.bool,
        'Black_Hair': tf.bool,
        'Blond_Hair': tf.bool,
        'Blurry': tf.bool,
        'Brown_Hair': tf.bool,
        'Bushy_Eyebrows': tf.bool,
        'Chubby': tf.bool,
        'Double_Chin': tf.bool,
        'Eyeglasses': tf.bool,
        'Goatee': tf.bool,
        'Gray_Hair': tf.bool,
        'Heavy_Makeup': tf.bool,
        'High_Cheekbones': tf.bool,
        'Male': tf.bool,
        'Mouth_Slightly_Open': tf.bool,
        'Mustache': tf.bool,
        'Narrow_Eyes': tf.bool,
        'No_Beard': tf.bool,
        'Oval_Face': tf.bool,
        'Pale_Skin': tf.bool,
        'Pointy_Nose': tf.bool,
        'Receding_Hairline': tf.bool,
        'Rosy_Cheeks': tf.bool,
        'Sideburns': tf.bool,
        'Smiling': tf.bool,
        'Straight_Hair': tf.bool,
        'Wavy_Hair': tf.bool,
        'Wearing_Earrings': tf.bool,
        'Wearing_Hat': tf.bool,
        'Wearing_Lipstick': tf.bool,
        'Wearing_Necklace': tf.bool,
        'Wearing_Necktie': tf.bool,
        'Young': tf.bool,
    }),
    'image': Image(shape=(218, 178, 3), dtype=tf.uint8),
    'landmarks': FeaturesDict({
        'lefteye_x': tf.int64,
        'lefteye_y': tf.int64,
        'leftmouth_x': tf.int64,
        'leftmouth_y': tf.int64,
        'nose_x': tf.int64,
        'nose_y': tf.int64,
        'righteye_x': tf.int64,
        'righteye_y': tf.int64,
        'rightmouth_x': tf.int64,
        'rightmouth_y': tf.int64,
    }),
})

*celeb_a_nq
FeaturesDict({
    'image': Image(shape=(1024, 1024, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
})

*clevr
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'objects': Sequence({
        '3d_coords': Tensor(shape=(3,), dtype=tf.float32),
        'color': ClassLabel(shape=(), dtype=tf.int64, num_classes=8),
        'material': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
        'pixel_coords': Tensor(shape=(3,), dtype=tf.float32),
        'rotation': tf.float32,
        'shape': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
        'size': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    }),
    'question_answer': Sequence({
        'answer': Text(shape=(), dtype=tf.string),
        'question': Text(shape=(), dtype=tf.string),
    }),
})

dsprites
FeaturesDict({
    'image': Image(shape=(64, 64, 1), dtype=tf.uint8),
    'label_orientation': ClassLabel(shape=(), dtype=tf.int64, num_classes=40),
    'label_scale': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),
    'label_shape': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
    'label_x_position': ClassLabel(shape=(), dtype=tf.int64, num_classes=32),
    'label_y_position': ClassLabel(shape=(), dtype=tf.int64, num_classes=32),
    'value_orientation': tf.float32,
    'value_scale': tf.float32,
    'value_shape': tf.float32,
    'value_x_position': tf.float32,
    'value_y_position': tf.float32,
})


duke_ultrasound
FeaturesDict({
    'das': FeaturesDict({
        'dB': Tensor(shape=(None,), dtype=tf.float32),
        'imag': Tensor(shape=(None,), dtype=tf.float32),
        'real': Tensor(shape=(None,), dtype=tf.float32),
    }),
    'dtce': Tensor(shape=(None,), dtype=tf.float32),
    'f0_hz': tf.float32,
    'final_angle': tf.float32,
    'final_radius': tf.float32,
    'focus_cm': tf.float32,
    'harmonic': tf.bool,
    'height': tf.uint32,
    'initial_angle': tf.float32,
    'initial_radius': tf.float32,
    'probe': tf.string,
    'scanner': tf.string,
    'target': tf.string,
    'timestamp_id': tf.uint32,
    'voltage': tf.float32,
    'width': tf.uint32,
})

flic
FeaturesDict({
    'currframe': tf.float64,
    'image': Image(shape=(480, 720, 3), dtype=tf.uint8),
    'moviename': Text(shape=(), dtype=tf.string),
    'poselet_hit_idx': Sequence(tf.uint16),
    'torsobox': BBoxFeature(shape=(4,), dtype=tf.float32),
    'xcoords': Sequence(tf.float64),
    'ycoords': Sequence(tf.float64),
})

lost_and_found
FeaturesDict({
    'image_id': Text(shape=(), dtype=tf.string),
    'image_left': Image(shape=(1024, 2048, 3), dtype=tf.uint8),
    'segmentation_label': Image(shape=(1024, 2048, 1), dtype=tf.uint8),
})

isun
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
})

nyu_depth_v2
FeaturesDict({
    'depth': Tensor(shape=(480, 640), dtype=tf.float16),
    'image': Image(shape=(480, 640, 3), dtype=tf.uint8),
})

scene_parse150
FeaturesDict({
    'annotation': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
})

shapes3d
FeaturesDict({
    'image': Image(shape=(64, 64, 3), dtype=tf.uint8),
    'label_floor_hue': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    'label_object_hue': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    'label_orientation': ClassLabel(shape=(), dtype=tf.int64, num_classes=15),
    'label_scale': ClassLabel(shape=(), dtype=tf.int64, num_classes=8),
    'label_shape': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),
    'label_wall_hue': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    'value_floor_hue': tf.float32,
    'value_object_hue': tf.float32,
    'value_orientation': tf.float32,
    'value_scale': tf.float32,
    'value_shape': tf.float32,
    'value_wall_hue': tf.float32,
})

the300w
FeaturesDict({
    'color_params': Tensor(shape=(7,), dtype=tf.float32),
    'exp_params': Tensor(shape=(29,), dtype=tf.float32),
    'illum_params': Tensor(shape=(10,), dtype=tf.float32),
    'image': Image(shape=(450, 450, 3), dtype=tf.uint8),
    'landmarks_2d': Tensor(shape=(68, 2), dtype=tf.float32),
    'landmarks_3d': Tensor(shape=(68, 2), dtype=tf.float32),
    'landmarks_origin': Tensor(shape=(68, 2), dtype=tf.float32),
    'pose_params': Tensor(shape=(7,), dtype=tf.float32),
    'roi': Tensor(shape=(4,), dtype=tf.float32),
    'shape_params': Tensor(shape=(199,), dtype=tf.float32),
    'tex_params': Tensor(shape=(199,), dtype=tf.float32),
})

#CLASSIFICATION
beans
FeaturesDict({
    'image': Image(shape=(500, 500, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
})

bigearthnet
FeaturesDict({
    'filename': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(120, 120, 3), dtype=tf.uint8),
    'labels': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=43)),
    'metadata': FeaturesDict({
        'acquisition_date': Text(shape=(), dtype=tf.string),
        'coordinates': FeaturesDict({
            'lrx': tf.int64,
            'lry': tf.int64,
            'ulx': tf.int64,
            'uly': tf.int64,
        }),
        'projection': Text(shape=(), dtype=tf.string),
        'tile_source': Text(shape=(), dtype=tf.string),
    }),
})

binary_alpha_digits
FeaturesDict({
    'image': Image(shape=(20, 16, 1), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=36),
})

caltech101
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/file_name': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=102),
})

caltech_birds2010
FeaturesDict({
    'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=200),
    'label_name': Text(shape=(), dtype=tf.string),
    'segmentation_mask': Image(shape=(None, None, 1), dtype=tf.uint8),
})

caltech_birds2011
FeaturesDict({
    'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=200),
    'label_name': Text(shape=(), dtype=tf.string),
    'segmentation_mask': Image(shape=(None, None, 1), dtype=tf.uint8),
})

cars196
FeaturesDict({
    'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=196),
})

cassava
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
})

cats_vs_dogs
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
})

cifar10
FeaturesDict({
    'id': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})

cifar100 (class, superclass)
FeaturesDict({
    'coarse_label': ClassLabel(shape=(), dtype=tf.int64, num_classes=20),
    'id': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=100),
})

cifar_10_1
FeaturesDict({
    'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})

cifar_10_corrupted
FeaturesDict({
    'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})

citrus_leaves
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),
})

cmaterdb
FeaturesDict({
    'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})

colorectal_histology
FeaturesDict({
    'filename': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(150, 150, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=8),
})

colorectal_histology_large
FeaturesDict({
    'filename': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(5000, 5000, 3), dtype=tf.uint8),
})

curated_breast_imaging_ddsm
FeaturesDict({
    'id': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 1), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
})

cycle_gan
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
})

deep_weeds
FeaturesDict({
    'image': Image(shape=(256, 256, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=9),
})

diabetic_retinopathy_detection
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
    'name': Text(shape=(), dtype=tf.string),
})

dmlab
FeaturesDict({
    'filename': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(360, 480, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),
})

dtd
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=47),
})

emnist
FeaturesDict({
    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=62),
})

eurosat
FeaturesDict({
    'filename': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(64, 64, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})

fashion_mnist
FeaturesDict({
    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})

food101
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=101),
})

geirhos_conflict_stimuli
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'shape_imagenet_labels': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=1000)),
    'shape_label': ClassLabel(shape=(), dtype=tf.int64, num_classes=16),
    'texture_imagenet_labels': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=1000)),
    'texture_label': ClassLabel(shape=(), dtype=tf.int64, num_classes=16),
})

horses_or_humans
FeaturesDict({
    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
})

i_naturalist2017
FeaturesDict({
    'id': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=5089),
    'supercategory': ClassLabel(shape=(), dtype=tf.int64, num_classes=13),
})

imagenet2012
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=1000),
})

imagenet2012_corrupted
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(224, 224, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=1000),
})

imagenet2012_real
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'original_label': ClassLabel(shape=(), dtype=tf.int64, num_classes=1000),
    'real_label': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=1000)),
})

imagenet2012_subset
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=1000),
})

imagenet_a
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=1000),
})

imagenet_resized
FeaturesDict({
    'image': Image(shape=(8, 8, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=1000),
})

imagenet_v2
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=1000),
})


imagenette
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})

imagewang
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=20),
})

kmnist
FeaturesDict({
    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})

lfw
FeaturesDict({
    'image': Image(shape=(250, 250, 3), dtype=tf.uint8),
    'label': Text(shape=(), dtype=tf.string),
})

malaria
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
})

mnist
FeaturesDict({
    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})

mnist_corrupted
FeaturesDict({
    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})

omniglot
FeaturesDict({
    'alphabet': ClassLabel(shape=(), dtype=tf.int64, num_classes=50),
    'alphabet_char_id': tf.int64,
    'image': Image(shape=(105, 105, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=1623),
})

oxford_flowers102
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=102),
})

oxford_iiit_pet
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=37),
    'segmentation_mask': Image(shape=(None, None, 1), dtype=tf.uint8),
    'species': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
})

patch_camelyon
FeaturesDict({
    'id': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(96, 96, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
})

pet_finder
FeaturesDict({
    'PetID': Text(shape=(), dtype=tf.string),
    'attributes': FeaturesDict({
        'Age': tf.int64,
        'Breed1': tf.int64,
        'Breed2': tf.int64,
        'Color1': tf.int64,
        'Color2': tf.int64,
        'Color3': tf.int64,
        'Dewormed': tf.int64,
        'Fee': tf.int64,
        'FurLength': tf.int64,
        'Gender': tf.int64,
        'Health': tf.int64,
        'MaturitySize': tf.int64,
        'Quantity': tf.int64,
        'State': tf.int64,
        'Sterilized': tf.int64,
        'Type': tf.int64,
        'Vaccinated': tf.int64,
        'VideoAmt': tf.int64,
    }),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
})

places365_small
FeaturesDict({
    'image': Image(shape=(256, 256, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=365),
})

plant_leaves
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=22),
})


plant_village
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=38),
})

plantae_k
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=16),
})

quickdraw_bitmap
FeaturesDict({
    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=345),
})

resisc45
FeaturesDict({
    'filename': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(256, 256, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=45),
})

rock_paper_scissors
FeaturesDict({
    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
})

smallnorb
FeaturesDict({
    'image': Image(shape=(96, 96, 1), dtype=tf.uint8),
    'image2': Image(shape=(96, 96, 1), dtype=tf.uint8),
    'instance': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    'label_azimuth': ClassLabel(shape=(), dtype=tf.int64, num_classes=18),
    'label_category': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
    'label_elevation': ClassLabel(shape=(), dtype=tf.int64, num_classes=9),
    'label_lighting': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),
})

so2sat
FeaturesDict({
    'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=17),
    'sample_id': tf.int64,
})

stanford_dogs
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=120),
    'objects': Sequence({
        'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
    }),
})

stanford_online_products
FeaturesDict({
    'class_id': ClassLabel(shape=(), dtype=tf.int64, num_classes=22634),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'super_class_id': ClassLabel(shape=(), dtype=tf.int64, num_classes=12),
    'super_class_id/num': ClassLabel(shape=(), dtype=tf.int64, num_classes=12),
})

stl10
FeaturesDict({
    'image': Image(shape=(96, 96, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})

sun397
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=397),
})

svhn_cropped
FeaturesDict({
    'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})

tf_flowers
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
})

uc_merced
FeaturesDict({
    'filename': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=21),
})

vgg_face2
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=9131),
})

visual_domain_decathlon
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=100),
    'name': Text(shape=(), dtype=tf.string),
})

#OBJECT DETECTION

coco
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'image/id': tf.int64,
    'objects': Sequence({
        'area': tf.int64,
        'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
        'id': tf.int64,
        'is_crowd': tf.bool,
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=80),
    }),
})

coco_captions
FeaturesDict({
    'captions': Sequence({
        'id': tf.int64,
        'text': tf.string,
    }),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'image/id': tf.int64,
    'objects': Sequence({
        'area': tf.int64,
        'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
        'id': tf.int64,
        'is_crowd': tf.bool,
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=80),
    }),
})

kitti
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/file_name': Text(shape=(), dtype=tf.string),
    'objects': Sequence({
        'alpha': tf.float32,
        'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
        'dimensions': Tensor(shape=(3,), dtype=tf.float32),
        'location': Tensor(shape=(3,), dtype=tf.float32),
        'occluded': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),
        'rotation_y': tf.float32,
        'truncated': tf.float32,
        'type': ClassLabel(shape=(), dtype=tf.int64, num_classes=8),
    }),
})

open_images_challenge2019_detection
FeaturesDict({
    'bobjects': Sequence({
        'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
        'is_group_of': tf.bool,
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=500),
    }),
    'id': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'objects': Sequence({
        'confidence': tf.float32,
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=500),
        'source': Text(shape=(), dtype=tf.string),
    }),
})

open_images_v4
FeaturesDict({
    'bobjects': Sequence({
        'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
        'is_depiction': tf.int8,
        'is_group_of': tf.int8,
        'is_inside': tf.int8,
        'is_occluded': tf.int8,
        'is_truncated': tf.int8,
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=601),
        'source': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),
    }),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'objects': Sequence({
        'confidence': tf.int32,
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=19995),
        'source': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),
    }),
    'objects_trainable': Sequence({
        'confidence': tf.int32,
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=7186),
        'source': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),
    }),
})

voc
FeaturesDict({
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
    'labels': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=20)),
    'labels_no_difficult': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=20)),
    'objects': Sequence({
        'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
        'is_difficult': tf.bool,
        'is_truncated': tf.bool,
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=20),
        'pose': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
    }),
})

waymo_open_dataset
FeaturesDict({
    'camera_FRONT': FeaturesDict({
        'image': Image(shape=(1280, 1920, 3), dtype=tf.uint8),
        'labels': Sequence({
            'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
            'type': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
        }),
    }),
    'camera_FRONT_LEFT': FeaturesDict({
        'image': Image(shape=(1280, 1920, 3), dtype=tf.uint8),
        'labels': Sequence({
            'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
            'type': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
        }),
    }),
    'camera_FRONT_RIGHT': FeaturesDict({
        'image': Image(shape=(1280, 1920, 3), dtype=tf.uint8),
        'labels': Sequence({
            'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
            'type': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
        }),
    }),
    'camera_SIDE_LEFT': FeaturesDict({
        'image': Image(shape=(886, 1920, 3), dtype=tf.uint8),
        'labels': Sequence({
            'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
            'type': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
        }),
    }),
    'camera_SIDE_RIGHT': FeaturesDict({
        'image': Image(shape=(886, 1920, 3), dtype=tf.uint8),
        'labels': Sequence({
            'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
            'type': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
        }),
    }),
    'context': FeaturesDict({
        'name': Text(shape=(), dtype=tf.string),
    }),
    'timestamp_micros': tf.int64,
})

wider_face
FeaturesDict({
    'faces': Sequence({
        'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
        'blur': tf.uint8,
        'expression': tf.bool,
        'illumination': tf.bool,
        'invalid': tf.bool,
        'occlusion': tf.uint8,
        'pose': tf.bool,
    }),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'image/filename': Text(shape=(), dtype=tf.string),
})

ai2_arc
FeaturesDict({
    'answerKey': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
    'choices': Sequence({
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
        'text': Text(shape=(), dtype=tf.string),
    }),
    'id': Text(shape=(), dtype=tf.string),
    'question': Text(shape=(), dtype=tf.string),
})

cosmos_qa
FeaturesDict({
    'answer0': Text(shape=(), dtype=tf.string),
    'answer1': Text(shape=(), dtype=tf.string),
    'answer2': Text(shape=(), dtype=tf.string),
    'answer3': Text(shape=(), dtype=tf.string),
    'context': Text(shape=(), dtype=tf.string),
    'id': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),
    'question': Text(shape=(), dtype=tf.string),
})

mctaco
FeaturesDict({
    'answer': Text(shape=(), dtype=tf.string),
    'category': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'question': Text(shape=(), dtype=tf.string),
    'sentence': Text(shape=(), dtype=tf.string),
})

natural_questions
FeaturesDict({
    'annotations': Sequence({
        'id': tf.string,
        'long_answer': FeaturesDict({
            'end_byte': tf.int64,
            'end_token': tf.int64,
            'start_byte': tf.int64,
            'start_token': tf.int64,
        }),
        'short_answers': Sequence({
            'end_byte': tf.int64,
            'end_token': tf.int64,
            'start_byte': tf.int64,
            'start_token': tf.int64,
            'text': Text(shape=(), dtype=tf.string),
        }),
        'yes_no_answer': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    }),
    'document': FeaturesDict({
        'html': Text(shape=(), dtype=tf.string),
        'title': Text(shape=(), dtype=tf.string),
        'tokens': Sequence({
            'is_html': tf.bool,
            'token': Text(shape=(), dtype=tf.string),
        }),
        'url': Text(shape=(), dtype=tf.string),
    }),
    'id': tf.string,
    'question': FeaturesDict({
        'text': Text(shape=(), dtype=tf.string),
        'tokens': Sequence(tf.string),
    }),
})

squad
FeaturesDict({
    'answers': Sequence({
        'answer_start': tf.int32,
        'text': Text(shape=(), dtype=tf.string),
    }),
    'context': Text(shape=(), dtype=tf.string),
    'id': tf.string,
    'question': Text(shape=(), dtype=tf.string),
    'title': Text(shape=(), dtype=tf.string),
})

trivia_qa
FeaturesDict({
    'answer': FeaturesDict({
        'aliases': Sequence(Text(shape=(), dtype=tf.string)),
        'matched_wiki_entity_name': Text(shape=(), dtype=tf.string),
        'normalized_aliases': Sequence(Text(shape=(), dtype=tf.string)),
        'normalized_matched_wiki_entity_name': Text(shape=(), dtype=tf.string),
        'normalized_value': Text(shape=(), dtype=tf.string),
        'type': Text(shape=(), dtype=tf.string),
        'value': Text(shape=(), dtype=tf.string),
    }),
    'entity_pages': Sequence({
        'doc_source': Text(shape=(), dtype=tf.string),
        'filename': Text(shape=(), dtype=tf.string),
        'title': Text(shape=(), dtype=tf.string),
        'wiki_context': Text(shape=(), dtype=tf.string),
    }),
    'question': Text(shape=(), dtype=tf.string),
    'question_id': Text(shape=(), dtype=tf.string),
    'question_source': Text(shape=(), dtype=tf.string),
    'search_results': Sequence({
        'description': Text(shape=(), dtype=tf.string),
        'filename': Text(shape=(), dtype=tf.string),
        'rank': tf.int32,
        'search_context': Text(shape=(), dtype=tf.string),
        'title': Text(shape=(), dtype=tf.string),
        'url': Text(shape=(), dtype=tf.string),
    }),
})

tydi_qa
FeaturesDict({
    'answers': Sequence({
        'answer_start': tf.int32,
        'text': Text(shape=(), dtype=tf.string),
    }),
    'context': Text(shape=(), dtype=tf.string),
    'id': tf.string,
    'question': Text(shape=(), dtype=tf.string),
    'title': Text(shape=(), dtype=tf.string),
})

web_questions
FeaturesDict({
    'answers': Sequence(Text(shape=(), dtype=tf.string)),
    'question': Text(shape=(), dtype=tf.string),
    'url': Text(shape=(), dtype=tf.string),
})

xquad
FeaturesDict({
    'answers': Sequence({
        'answer_start': tf.int32,
        'text': Text(shape=(), dtype=tf.string),
    }),
    'context': Text(shape=(), dtype=tf.string),
    'id': tf.string,
    'question': Text(shape=(), dtype=tf.string),
    'title': Text(shape=(), dtype=tf.string),
})

#STRUCTURED
amazon_us_reviews
FeaturesDict({
    'data': FeaturesDict({
        'customer_id': tf.string,
        'helpful_votes': tf.int32,
        'marketplace': tf.string,
        'product_category': tf.string,
        'product_id': tf.string,
        'product_parent': tf.string,
        'product_title': tf.string,
        'review_body': tf.string,
        'review_date': tf.string,
        'review_headline': tf.string,
        'review_id': tf.string,
        'star_rating': tf.int32,
        'total_votes': tf.int32,
        'verified_purchase': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
        'vine': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    }),
})

forest_fires
FeaturesDict({
    'area': tf.float32,
    'features': FeaturesDict({
        'DC': tf.float32,
        'DMC': tf.float32,
        'FFMC': tf.float32,
        'ISI': tf.float32,
        'RH': tf.float32,
        'X': tf.uint8,
        'Y': tf.uint8,
        'day': ClassLabel(shape=(), dtype=tf.int64, num_classes=7),
        'month': ClassLabel(shape=(), dtype=tf.int64, num_classes=12),
        'rain': tf.float32,
        'temp': tf.float32,
        'wind': tf.float32,
    }),
})

genomics_ood
FeaturesDict({
    'domain': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=130),
    'seq': Text(shape=(), dtype=tf.string),
    'seq_info': Text(shape=(), dtype=tf.string),
})

german_credit_numeric
FeaturesDict({
    'features': Tensor(shape=(24,), dtype=tf.int32),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
})

higgs
FeaturesDict({
    'class_label': tf.float32,
    'jet_1_b-tag': tf.float64,
    'jet_1_eta': tf.float64,
    'jet_1_phi': tf.float64,
    'jet_1_pt': tf.float64,
    'jet_2_b-tag': tf.float64,
    'jet_2_eta': tf.float64,
    'jet_2_phi': tf.float64,
    'jet_2_pt': tf.float64,
    'jet_3_b-tag': tf.float64,
    'jet_3_eta': tf.float64,
    'jet_3_phi': tf.float64,
    'jet_3_pt': tf.float64,
    'jet_4_b-tag': tf.float64,
    'jet_4_eta': tf.float64,
    'jet_4_phi': tf.float64,
    'jet_4_pt': tf.float64,
    'lepton_eta': tf.float64,
    'lepton_pT': tf.float64,
    'lepton_phi': tf.float64,
    'm_bb': tf.float64,
    'm_jj': tf.float64,
    'm_jjj': tf.float64,
    'm_jlv': tf.float64,
    'm_lv': tf.float64,
    'm_wbb': tf.float64,
    'm_wwbb': tf.float64,
    'missing_energy_magnitude': tf.float64,
    'missing_energy_phi': tf.float64,
})

iris
FeaturesDict({
    'features': Tensor(shape=(4,), dtype=tf.float32),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
})

movie_lens
FeaturesDict({
    'movie_genres': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=21)),
    'movie_id': tf.string,
    'movie_title': tf.string,
    'timestamp': tf.int64,
    'user_id': tf.string,
    'user_rating': tf.float32,
})

movielens
FeaturesDict({
    'movie_genres': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=21)),
    'movie_id': tf.string,
    'movie_title': tf.string,
    'timestamp': tf.int64,
    'user_id': tf.string,
    'user_rating': tf.float32,
})

radon
FeaturesDict({
    'activity': tf.float32,
    'features': FeaturesDict({
        'Uppm': tf.float32,
        'adjwt': tf.float32,
        'basement': tf.string,
        'cntyfips': tf.int32,
        'county': tf.string,
        'dupflag': tf.int32,
        'floor': tf.int32,
        'idnum': tf.int32,
        'lat': tf.float32,
        'lon': tf.float32,
        'pcterr': tf.float32,
        'region': tf.int32,
        'rep': tf.int32,
        'room': tf.int32,
        'startdt': tf.int32,
        'starttm': tf.int32,
        'state': tf.string,
        'state2': tf.string,
        'stfips': tf.int32,
        'stopdt': tf.int32,
        'stoptm': tf.int32,
        'stratum': tf.int32,
        'typebldg': tf.int32,
        'wave': tf.int32,
        'windoor': tf.string,
        'zip': tf.int32,
        'zipflag': tf.int32,
    }),
})

rock_you
FeaturesDict({
    'password': Text(shape=(None,), dtype=tf.int64, encoder=<ByteTextEncoder vocab_size=257>),
})

titanic
FeaturesDict({
    'features': FeaturesDict({
        'age': tf.float32,
        'boat': tf.string,
        'body': tf.int32,
        'cabin': tf.string,
        'embarked': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),
        'fare': tf.float32,
        'home.dest': tf.string,
        'name': tf.string,
        'parch': tf.int32,
        'pclass': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
        'sex': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
        'sibsp': tf.int32,
        'ticket': tf.string,
    }),
    'survived': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
})

#SUMMARIZATION

aeslc
FeaturesDict({
    'email_body': Text(shape=(), dtype=tf.string),
    'subject_line': Text(shape=(), dtype=tf.string),
})

big_patent
FeaturesDict({
    'abstract': Text(shape=(), dtype=tf.string),
    'description': Text(shape=(), dtype=tf.string),
})

billsum
FeaturesDict({
    'summary': Text(shape=(), dtype=tf.string),
    'text': Text(shape=(), dtype=tf.string),
    'title': Text(shape=(), dtype=tf.string),
})

cnn_dailymail
FeaturesDict({
    'article': Text(shape=(), dtype=tf.string),
    'highlights': Text(shape=(), dtype=tf.string),
})

covid19sum
FeaturesDict({
    'abstract': tf.string,
    'authors': tf.string,
    'body_text': Sequence({
        'section': tf.string,
        'text': tf.string,
    }),
    'doi': tf.string,
    'journal': tf.string,
    'license': tf.string,
    'publish_time': tf.string,
    'sha': tf.string,
    'source_x': tf.string,
    'title': tf.string,
    'url': tf.string,
})

gigaword
FeaturesDict({
    'document': Text(shape=(), dtype=tf.string),
    'summary': Text(shape=(), dtype=tf.string),
})

multi_news
FeaturesDict({
    'document': Text(shape=(), dtype=tf.string),
    'summary': Text(shape=(), dtype=tf.string),
})

newsroom
FeaturesDict({
    'compression': tf.float32,
    'compression_bin': Text(shape=(), dtype=tf.string),
    'coverage': tf.float32,
    'coverage_bin': Text(shape=(), dtype=tf.string),
    'date': Text(shape=(), dtype=tf.string),
    'density': tf.float32,
    'density_bin': Text(shape=(), dtype=tf.string),
    'summary': Text(shape=(), dtype=tf.string),
    'text': Text(shape=(), dtype=tf.string),
    'title': Text(shape=(), dtype=tf.string),
    'url': Text(shape=(), dtype=tf.string),
})

opinion_abstracts
FeaturesDict({
    '_critic_consensus': tf.string,
    '_critics': Sequence({
        'key': tf.string,
        'value': tf.string,
    }),
    '_movie_id': tf.string,
    '_movie_name': tf.string,
})

opinosis
FeaturesDict({
    'review_sents': Text(shape=(), dtype=tf.string),
    'summaries': Sequence(Text(shape=(), dtype=tf.string)),
})

reddit
FeaturesDict({
    'author': tf.string,
    'body': tf.string,
    'content': tf.string,
    'id': tf.string,
    'normalizedBody': tf.string,
    'subreddit': tf.string,
    'subreddit_id': tf.string,
    'summary': tf.string,
})

reddit_tifu
FeaturesDict({
    'documents': Text(shape=(), dtype=tf.string),
    'num_comments': tf.float32,
    'score': tf.float32,
    'title': Text(shape=(), dtype=tf.string),
    'tldr': Text(shape=(), dtype=tf.string),
    'ups': tf.float32,
    'upvote_ratio': tf.float32,
})

samsum
FeaturesDict({
    'dialogue': Text(shape=(), dtype=tf.string),
    'id': Text(shape=(), dtype=tf.string),
    'summary': Text(shape=(), dtype=tf.string),
})

scientific_papers
FeaturesDict({
    'abstract': Text(shape=(), dtype=tf.string),
    'article': Text(shape=(), dtype=tf.string),
    'section_names': Text(shape=(), dtype=tf.string),
})

wikihow
FeaturesDict({
    'headline': Text(shape=(), dtype=tf.string),
    'text': Text(shape=(), dtype=tf.string),
    'title': Text(shape=(), dtype=tf.string),
})

xsum
FeaturesDict({
    'document': Text(shape=(), dtype=tf.string),
    'summary': Text(shape=(), dtype=tf.string),
})

#TEXT

ag_news_subset
FeaturesDict({
    'description': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),
    'title': Text(shape=(), dtype=tf.string),
})

anli
FeaturesDict({
    'context': Text(shape=(), dtype=tf.string),
    'hypothesis': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
    'uid': Text(shape=(), dtype=tf.string),
})

blimp
FeaturesDict({
    'UID': Text(shape=(), dtype=tf.string),
    'field': Text(shape=(), dtype=tf.string),
    'lexically_identical': tf.bool,
    'linguistics_term': Text(shape=(), dtype=tf.string),
    'one_prefix_method': tf.bool,
    'pair_id': tf.int32,
    'sentence_bad': Text(shape=(), dtype=tf.string),
    'sentence_good': Text(shape=(), dtype=tf.string),
    'simple_LM_method': tf.bool,
    'two_prefix_method': tf.bool,
})

c4
FeaturesDict({
    'content-length': Text(shape=(), dtype=tf.string),
    'content-type': Text(shape=(), dtype=tf.string),
    'text': Text(shape=(), dtype=tf.string),
    'timestamp': Text(shape=(), dtype=tf.string),
    'url': Text(shape=(), dtype=tf.string),
})

cfq
FeaturesDict({
    'query': Text(shape=(), dtype=tf.string),
    'question': Text(shape=(), dtype=tf.string),
})

civil_comments
FeaturesDict({
    'identity_attack': tf.float32,
    'insult': tf.float32,
    'obscene': tf.float32,
    'severe_toxicity': tf.float32,
    'sexual_explicit': tf.float32,
    'text': Text(shape=(), dtype=tf.string),
    'threat': tf.float32,
    'toxicity': tf.float32,
})

clinc_oos
FeaturesDict({
    'domain': tf.int32,
    'domain_name': Text(shape=(), dtype=tf.string),
    'intent': tf.int32,
    'intent_name': Text(shape=(), dtype=tf.string),
    'text': Text(shape=(), dtype=tf.string),
})

cos_e
FeaturesDict({
    'abstractive_explanation': Text(shape=(), dtype=tf.string),
    'answer': Text(shape=(), dtype=tf.string),
    'choices': Sequence(Text(shape=(), dtype=tf.string)),
    'extractive_explanation': Text(shape=(), dtype=tf.string),
    'id': Text(shape=(), dtype=tf.string),
    'question': Text(shape=(), dtype=tf.string),
})

definite_pronoun_resolution
FeaturesDict({
    'candidates': Sequence(Text(shape=(), dtype=tf.string)),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'pronoun': Text(shape=(), dtype=tf.string),
    'sentence': Text(shape=(), dtype=tf.string),
})

eraser_multi_rc
FeaturesDict({
    'evidences': Sequence(Text(shape=(), dtype=tf.string)),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'passage': Text(shape=(), dtype=tf.string),
    'query_and_answer': Text(shape=(), dtype=tf.string),
})

esnli
FeaturesDict({
    'explanation_1': Text(shape=(), dtype=tf.string),
    'explanation_2': Text(shape=(), dtype=tf.string),
    'explanation_3': Text(shape=(), dtype=tf.string),
    'hypothesis': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
    'premise': Text(shape=(), dtype=tf.string),
})

gap
FeaturesDict({
    'A': Text(shape=(), dtype=tf.string),
    'A-coref': tf.bool,
    'A-offset': tf.int32,
    'B': Text(shape=(), dtype=tf.string),
    'B-coref': tf.bool,
    'B-offset': tf.int32,
    'ID': Text(shape=(), dtype=tf.string),
    'Pronoun': Text(shape=(), dtype=tf.string),
    'Pronoun-offset': tf.int32,
    'Text': Text(shape=(), dtype=tf.string),
    'URL': Text(shape=(), dtype=tf.string),
})

glue
FeaturesDict({
    'idx': tf.int32,
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'sentence': Text(shape=(), dtype=tf.string),
})

goemotions
FeaturesDict({
    'admiration': tf.bool,
    'amusement': tf.bool,
    'anger': tf.bool,
    'annoyance': tf.bool,
    'approval': tf.bool,
    'caring': tf.bool,
    'comment_text': Text(shape=(), dtype=tf.string),
    'confusion': tf.bool,
    'curiosity': tf.bool,
    'desire': tf.bool,
    'disappointment': tf.bool,
    'disapproval': tf.bool,
    'disgust': tf.bool,
    'embarrassment': tf.bool,
    'excitement': tf.bool,
    'fear': tf.bool,
    'gratitude': tf.bool,
    'grief': tf.bool,
    'joy': tf.bool,
    'love': tf.bool,
    'nervousness': tf.bool,
    'neutral': tf.bool,
    'optimism': tf.bool,
    'pride': tf.bool,
    'realization': tf.bool,
    'relief': tf.bool,
    'remorse': tf.bool,
    'sadness': tf.bool,
    'surprise': tf.bool,
})

imdb_reviews
FeaturesDict({
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'text': Text(shape=(), dtype=tf.string),
})

irc_disentanglement
FeaturesDict({
    'day': Sequence({
        'id': Text(shape=(), dtype=tf.string),
        'parents': Sequence(Text(shape=(), dtype=tf.string)),
        'text': Text(shape=(), dtype=tf.string),
        'timestamp': Text(shape=(), dtype=tf.string),
    }),
})

librispeech_lm
FeaturesDict({
    'text': Text(shape=(), dtype=tf.string),
})

lm1b
FeaturesDict({
    'text': Text(shape=(), dtype=tf.string),
})

math_dataset
FeaturesDict({
    'answer': Text(shape=(), dtype=tf.string),
    'question': Text(shape=(), dtype=tf.string),
})

movie_rationales
FeaturesDict({
    'evidences': Sequence(Text(shape=(), dtype=tf.string)),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'review': Text(shape=(), dtype=tf.string),
})

multi_nli
FeaturesDict({
    'hypothesis': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
    'premise': Text(shape=(), dtype=tf.string),
})

multi_nli_mismatch
FeaturesDict({
    'hypothesis': Text(shape=(), dtype=tf.string),
    'label': Text(shape=(), dtype=tf.string),
    'premise': Text(shape=(), dtype=tf.string),
})

openbookqa
FeaturesDict({
    'answerKey': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),
    'clarity': tf.float32,
    'fact1': Text(shape=(), dtype=tf.string),
    'humanScore': tf.float32,
    'question': FeaturesDict({
        'choice_A': Text(shape=(), dtype=tf.string),
        'choice_B': Text(shape=(), dtype=tf.string),
        'choice_C': Text(shape=(), dtype=tf.string),
        'choice_D': Text(shape=(), dtype=tf.string),
        'stem': Text(shape=(), dtype=tf.string),
    }),
    'turkIdAnonymized': Text(shape=(), dtype=tf.string),
})

paws_wiki
FeaturesDict({
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'sentence1': Text(shape=(), dtype=tf.string),
    'sentence2': Text(shape=(), dtype=tf.string),
})

pg19
FeaturesDict({
    'book_id': tf.int32,
    'book_link': tf.string,
    'book_text': Text(shape=(), dtype=tf.string),
    'book_title': tf.string,
    'publication_date': tf.string,
})

qa4mre
FeaturesDict({
    'answer_options': Sequence({
        'answer_id': Text(shape=(), dtype=tf.string),
        'answer_str': Text(shape=(), dtype=tf.string),
    }),
    'correct_answer_id': Text(shape=(), dtype=tf.string),
    'correct_answer_str': Text(shape=(), dtype=tf.string),
    'document_id': Text(shape=(), dtype=tf.string),
    'document_str': Text(shape=(), dtype=tf.string),
    'question_id': Text(shape=(), dtype=tf.string),
    'question_str': Text(shape=(), dtype=tf.string),
    'test_id': Text(shape=(), dtype=tf.string),
    'topic_id': Text(shape=(), dtype=tf.string),
    'topic_name': Text(shape=(), dtype=tf.string),
})

reddit_disentanglement
FeaturesDict({
    'thread': Sequence({
        'author': Text(shape=(), dtype=tf.string),
        'created_utc': Text(shape=(), dtype=tf.string),
        'id': Text(shape=(), dtype=tf.string),
        'link_id': Text(shape=(), dtype=tf.string),
        'parent_id': Text(shape=(), dtype=tf.string),
        'text': Text(shape=(), dtype=tf.string),
    }),
})

scan
FeaturesDict({
    'actions': Text(shape=(), dtype=tf.string),
    'commands': Text(shape=(), dtype=tf.string),
})

scicite
FeaturesDict({
    'citeEnd': tf.int64,
    'citeStart': tf.int64,
    'citedPaperId': Text(shape=(), dtype=tf.string),
    'citingPaperId': Text(shape=(), dtype=tf.string),
    'excerpt_index': tf.int32,
    'id': Text(shape=(), dtype=tf.string),
    'isKeyCitation': tf.bool,
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
    'label2': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),
    'label2_confidence': tf.float32,
    'label_confidence': tf.float32,
    'sectionName': Text(shape=(), dtype=tf.string),
    'source': ClassLabel(shape=(), dtype=tf.int64, num_classes=7),
    'string': Text(shape=(), dtype=tf.string),
})

snli
FeaturesDict({
    'hypothesis': Text(shape=(), dtype=tf.string),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
    'premise': Text(shape=(), dtype=tf.string),
})

super_glue
FeaturesDict({
    'idx': tf.int32,
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'passage': Text(shape=(), dtype=tf.string),
    'question': Text(shape=(), dtype=tf.string),
})

tiny_shakespeare
FeaturesDict({
    'text': Text(shape=(), dtype=tf.string),
})

wiki40b
FeaturesDict({
    'text': Text(shape=(), dtype=tf.string),
    'version_id': Text(shape=(), dtype=tf.string),
    'wikidata_id': Text(shape=(), dtype=tf.string),
})

wikipedia
FeaturesDict({
    'text': Text(shape=(), dtype=tf.string),
    'title': Text(shape=(), dtype=tf.string),
})

wikipedia_toxicity_subtypes
FeaturesDict({
    'identity_attack': tf.float32,
    'insult': tf.float32,
    'obscene': tf.float32,
    'severe_toxicity': tf.float32,
    'text': Text(shape=(), dtype=tf.string),
    'threat': tf.float32,
    'toxicity': tf.float32,
})

winogrande
FeaturesDict({
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'option1': Text(shape=(), dtype=tf.string),
    'option2': Text(shape=(), dtype=tf.string),
    'sentence': Text(shape=(), dtype=tf.string),
})

wordnet
FeaturesDict({
    'lhs': Text(shape=(), dtype=tf.string),
    'relation': Text(shape=(), dtype=tf.string),
    'rhs': Text(shape=(), dtype=tf.string),
})

xnli
FeaturesDict({
    'hypothesis': TranslationVariableLanguages({
        'language': Text(shape=(), dtype=tf.string),
        'translation': Text(shape=(), dtype=tf.string),
    }),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),
    'premise': Translation({
        'ar': Text(shape=(), dtype=tf.string),
        'bg': Text(shape=(), dtype=tf.string),
        'de': Text(shape=(), dtype=tf.string),
        'el': Text(shape=(), dtype=tf.string),
        'en': Text(shape=(), dtype=tf.string),
        'es': Text(shape=(), dtype=tf.string),
        'fr': Text(shape=(), dtype=tf.string),
        'hi': Text(shape=(), dtype=tf.string),
        'ru': Text(shape=(), dtype=tf.string),
        'sw': Text(shape=(), dtype=tf.string),
        'th': Text(shape=(), dtype=tf.string),
        'tr': Text(shape=(), dtype=tf.string),
        'ur': Text(shape=(), dtype=tf.string),
        'vi': Text(shape=(), dtype=tf.string),
        'zh': Text(shape=(), dtype=tf.string),
    }),
})

yelp_polarity_reviews
FeaturesDict({
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'text': Text(shape=(), dtype=tf.string),
})

#TRANSLATION

flores
Translation({
    'en': Text(shape=(), dtype=tf.string),
    'ne': Text(shape=(), dtype=tf.string),
})


opus
Translation({
    'de': Text(shape=(), dtype=tf.string),
    'en': Text(shape=(), dtype=tf.string),
})

para_crawl
Translation({
    'bg': Text(shape=(), dtype=tf.string),
    'en': Text(shape=(), dtype=tf.string),
})

ted_hrlr_translate
Translation({
    'az': Text(shape=(), dtype=tf.string),
    'en': Text(shape=(), dtype=tf.string),
})

ted_multi_translate
FeaturesDict({
    'talk_name': Text(shape=(), dtype=tf.string),
    'translations': TranslationVariableLanguages({
        'language': Text(shape=(), dtype=tf.string),
        'translation': Text(shape=(), dtype=tf.string),
    }),
})

bair_robot_pushing_small
Sequence({
    'action': Tensor(shape=(4,), dtype=tf.float32),
    'endeffector_pos': Tensor(shape=(3,), dtype=tf.float32),
    'image_aux1': Image(shape=(64, 64, 3), dtype=tf.uint8),
    'image_main': Image(shape=(64, 64, 3), dtype=tf.uint8),
})

moving_mnist
FeaturesDict({
    'image_sequence': Video(Image(shape=(64, 64, 1), dtype=tf.uint8)),
})

robonet
FeaturesDict({
    'actions': Tensor(shape=(None, 5), dtype=tf.float32),
    'states': Tensor(shape=(None, 5), dtype=tf.float32),
    'video': Video(Image(shape=(64, 64, 3), dtype=tf.uint8)),
})

starcraft_video
FeaturesDict({
    'rgb_screen': Video(Image(shape=(128, 128, 3), dtype=tf.uint8)),
})

ucf101
FeaturesDict({
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=101),
    'video': Video(Image(shape=(256, 256, 3), dtype=tf.uint8)),
})
